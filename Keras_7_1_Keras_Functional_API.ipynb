{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Functional API\n",
    "Predict most likely market price of a second-hand piece of clothing with the following inputs:\n",
    "1. User-provided metadata - such as the item's brand, age, and so on\n",
    "2. User provided text description\n",
    "3. Picture of the item\n",
    "\n",
    "only metadata - one-hot encode it and use a densely connected network to predict the price\n",
    "only text description - use an RNN or 1D convnet\n",
    "only picture - use a 2D convnet\n",
    "\n",
    "But how would you use all 3 at the same time?\n",
    "Naive approach: train all three models and then do a weighted average of the predictions. Probably suboptimal\n",
    "\n",
    "Better approach: *jointly* learn a more accurate model of the data by using a model that can see ALL AVAILABLE INPUT modalities\n",
    "\n",
    "More examples: \"Inception\" modules, where input is processed by several parallel convolutional branches whose output is processed by sevearl parallel convolutional branches whose outputs are then merged back into a single tensor.\n",
    "\n",
    "Residual connections: reinject previous representations into the downstream flow of data by adding pas output tensor to a lter output tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-By-Side - Keras Functional vs Sequential Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "?layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, None, 32)          1056      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, None, 10)          330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "print(model.summary())\n",
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_train, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "?layers.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 10000)  640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           1284224     embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 16)           641088      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 48)           0           lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 500)          24500       concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,909,812\n",
      "Trainable params: 2,909,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding data into multi-input model\n",
    "import numpy as np\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length)) #questions are ... ?\n",
    "answer = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size)) #integers are One Hot Encoded, not ints\n",
    "\n",
    "model.fit([text, question], answer, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-output Models\n",
    "\n",
    "Simple network that attempts to simultaneously predict different properties of the data.\n",
    "* example - social media posts used to predict age, gender, income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced loss contributions\n",
    "Will cause model representations to be optimized preferentially for the task with the largest individual loss.\n",
    "\n",
    "For example\n",
    "* MSE loss for age-regression is 3-5\n",
    "* cross_entropy loss can be as low as 0.1 for gender classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], \n",
    "             loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "### equivilent\n",
    "model.compile(optimizer='rmsprop', \n",
    "             loss={'age': 'mse', 'income': 'categorical_crossentropy', 'gender': 'binary_crossentropy'},\n",
    "             loss_weights={'age': 0.25, 'income': 1., 'gender': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(posts, {'age': age_targets, 'income': income_targets, 'gender': gender_targets}, epochs = 10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed, Acyclic Graphs\n",
    "Both of these words are imported\n",
    "* Directed: Having 1 direction\n",
    "* Acyclic: Graphs can not have CYCLES. It's impossible for tensor X to become input of one of the layers that generated X\n",
    "* Only processing loops allowed are internal to the layers (like RNNs and GRU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception model\n",
    "Inception V3 module will be coded below. Notice how there are 4 smaller networks before the cancatenate step\n",
    "* Network 1: Conv2D - 1x1, strides = 2\n",
    "* Network 2: Conv2d - 1x1 --> Conv2D 3x3, strides = 2\n",
    "* Network 3: AvgPool2D 3x3, strides=2 --> Conv2D 3x3\n",
    "* Network 4: Conv2D 1x1 --> Conv2D 3x3 --> Conv 2D 3x3, strides=2\n",
    "\n",
    "Actual inception model: \n",
    "keras.applications.inception_v3.InceptionV3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "?layers.Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pgbpr\\Anaconda2\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "x = Input(shape=(None,128,128), dtype='float32', name='posts') #a 4D input tensor, I guess\n",
    "\n",
    "branch_a = layers.Conv2D(filters=128, kernel_size=1, activation='relu', strides=2, padding='same')(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu', padding='same')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2, padding='same')(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu', padding='same')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', padding='same', strides=2)(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual connections\n",
    "A residual connection consists of making the output of an earlier layer available as input to a lter layer, creating a shortcut. \n",
    "\n",
    "The example assumes a 4D input tensor x. X will be added BACK to an otherwise sequential model after we've put X though a couple of convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x]) #Adds original x back to the output features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Residual connection when feature-map sizes differ (using downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "#uses a 1x1 convolution to linarly downsample the original x tesnro to the same shape as y\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x) \n",
    "\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representational Bottlenecks in Machine learning\n",
    "\n",
    "Sequential model: layer built on previous layer. Any information lost is permanent\n",
    "Residual model: reinject previous layers into later layers. Partially solve information loss problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing gradients in Deep learning\n",
    "Propogating a feedback signal from the output loss down to earlier layers.\n",
    "If this signal has to be propogated through a deep stack of layers, the signal may become tenuous or lost.\n",
    "\n",
    "LSTM: introduce a carry track that propogates information parallel to the main processing track.\n",
    "Residual: introduce a purely linear information carry track parallel to the main processing track. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Weight sharing\n",
    "(This is very important to me, I think, in trying to get the Siamese neural network to work)\n",
    "Reuse a layer instance several times. When you call a layer instance twice, you reuse the same weights with every call. \n",
    "\n",
    "This allows you to build models that have shared branches-several branches that all share the same knowledge and perform the same operations. They share the same representations and learn these representations SIMULTANEOUSLY for different sets of inputs.\n",
    "\n",
    "Consider a model that attempts to assess the semantic similarity between two sentences. The model has two inputs (the two sentences to compare) and outputs a score between 0 and 1, where 0 means unrelated sentences and 1 means sentences that are either identical or reformulations of each other. \n",
    "\n",
    "In this setup, the two input sentences are interchangeable, because semantic similarity is a symmetric relationship: the similarity of A to B is identical to the similarity of B to A. For this reason, independent models don't make sense. \n",
    "\n",
    "This is called a Siamese LSTM or shared LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32) #instantiating a layer\n",
    "\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input) #using that previously instantiated layer first time\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input) #REUSING the previously instantiated layer :)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models AS layers\n",
    "You can think of a model as a bigger layer. True of both Sequential and Model classes. You can call a model on an input tensor and retrieve an output tensor.\n",
    "\n",
    "y = model(x)\n",
    "\n",
    "Or if, multiple input tensors / multiple output tensors you can do like this\n",
    "\n",
    "y1, y2 = model([x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Vision Model\n",
    "Two parallel camaeras, a few inches apart. Don't need two SEPERATE networks for low level processing.\n",
    "So the first part of the processing can be done via layers that use the same weights and thus share the same representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
